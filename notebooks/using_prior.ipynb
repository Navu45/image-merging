{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import KandinskyV22PriorEmb2EmbPipeline\n",
    "\n",
    "from models.combined_pipeline_prior import CombinedPipelineV2\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-21T22:55:03.561744Z",
     "end_time": "2023-10-21T22:55:03.572740Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "Loading pipeline components...:   0%|          | 0/9 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5e7f8283e7864fe882f0e6639801288c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "decoder = CombinedPipelineV2.from_pretrained(\"../models/weights/img2img-painting\", torch_dtype=torch.float16, variant=\"fp16\", use_safetensors=True)\n",
    "decoder.enable_model_cpu_offload()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-21T22:55:03.806763Z",
     "end_time": "2023-10-21T22:55:05.861760Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "text_encoder\\model.safetensors not found\n"
     ]
    },
    {
     "data": {
      "text/plain": "Loading pipeline components...:   0%|          | 0/6 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3c6d54d447924b13914947cddfe5f6ca"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prior = KandinskyV22PriorEmb2EmbPipeline.from_pretrained('kandinsky-community/kandinsky-2-2-prior',\n",
    "                                                         image_encoder=decoder.image_encoder,\n",
    "                                                         scheduler=decoder.scheduler,\n",
    "                                                         image_processor=decoder.image_processor,\n",
    "                                                         torch_dtype=torch.float16)\n",
    "prior.enable_model_cpu_offload()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-21T22:55:05.863761Z",
     "end_time": "2023-10-21T22:55:08.965497Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "<torch._C.Generator at 0x1eaddbe2cf0>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_prior_prompt ='lowres, text, error, cropped, worst quality, low quality, jpeg artifacts, ugly, duplicate, morbid, mutilated, out of frame, extra fingers, mutated hands, poorly drawn hands, poorly drawn face, mutation, deformed, blurry, dehydrated, bad anatomy, bad proportions, extra limbs, cloned face, disfigured, gross proportions, malformed limbs, missing arms, missing legs, extra arms, extra legs, fused fingers, too many fingers, long neck, username, watermark, signature'\n",
    "torch.manual_seed(42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-21T22:55:08.966495Z",
     "end_time": "2023-10-21T22:55:08.980496Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[13], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m negative_prior_prompt \u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlowres, text, error, cropped, worst quality, low quality, jpeg artifacts, ugly, duplicate, morbid, mutilated, out of frame, extra fingers, mutated hands, poorly drawn hands, poorly drawn face, mutation, deformed, blurry, dehydrated, bad anatomy, bad proportions, extra limbs, cloned face, disfigured, gross proportions, malformed limbs, missing arms, missing legs, extra arms, extra legs, fused fingers, too many fingers, long neck, username, watermark, signature\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m      2\u001B[0m torch\u001B[38;5;241m.\u001B[39mmanual_seed(\u001B[38;5;241m42\u001B[39m)\n\u001B[1;32m----> 3\u001B[0m clip_img_emb \u001B[38;5;241m=\u001B[39m prior\u001B[38;5;241m.\u001B[39minterpolate(images_and_prompts\u001B[38;5;241m=\u001B[39m[\u001B[43mimg\u001B[49m], weights\u001B[38;5;241m=\u001B[39m[\u001B[38;5;241m1\u001B[39m], num_images_per_prompt\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, )\u001B[38;5;241m.\u001B[39mimage_embeds\n\u001B[0;32m      4\u001B[0m img_emb \u001B[38;5;241m=\u001B[39m prior(prompt\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mA capybara, 4k photo\u001B[39m\u001B[38;5;124m'\u001B[39m, image\u001B[38;5;241m=\u001B[39mclip_img_emb, strength\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.85\u001B[39m, num_inference_steps\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m25\u001B[39m, num_images_per_prompt\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,)\n\u001B[0;32m      5\u001B[0m negative_emb \u001B[38;5;241m=\u001B[39m prior(prompt\u001B[38;5;241m=\u001B[39mnegative_prior_prompt, image\u001B[38;5;241m=\u001B[39mclip_img_emb, strength\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, num_inference_steps\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m25\u001B[39m, num_images_per_prompt\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'img' is not defined"
     ]
    }
   ],
   "source": [
    "def generate_with_prior(source_image, target_image):\n",
    "    clip_img_emb = prior.interpolate(images_and_prompts=[source_image, target_image],\n",
    "                                     weights=[1],\n",
    "                                     num_images_per_prompt=1, ).image_embeds\n",
    "    img_emb = prior(prompt='a human being wearing some clothes in front of a white background',\n",
    "                    image=clip_img_emb,\n",
    "                    strength=0.85,\n",
    "                    num_inference_steps=25,\n",
    "                    num_images_per_prompt=1,)\n",
    "    negative_emb = prior(prompt=negative_prior_prompt,\n",
    "                         image=clip_img_emb,\n",
    "                         strength=1,\n",
    "                         num_inference_steps=25,\n",
    "                         num_images_per_prompt=1)\n",
    "    images = decoder(image=img,\n",
    "                     strength=0.5,\n",
    "                     image_embeds=img_emb.image_embeds,\n",
    "                     negative_image_embeds=negative_emb.image_embeds,\n",
    "                     num_inference_steps=50,\n",
    "                     height=512, width=512)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
