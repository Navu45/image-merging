{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# !pip install git+https://github.com/Navu45/image-merging.git\n",
    "# !pip install git+https://github.com/ChaoningZhang/MobileSAM.git"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-16T18:15:51.968845Z",
     "end_time": "2023-10-16T18:15:52.000914Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from PIL import Image\n",
    "from diffusers import DDIMScheduler\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "\n",
    "from models.inpaint_image import InpaintPipeline"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-16T18:15:51.985915Z",
     "end_time": "2023-10-16T18:15:55.687513Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-10-16T18:15:55.688514Z",
     "end_time": "2023-10-16T18:16:01.844622Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unet\\diffusion_pytorch_model.safetensors not found\n"
     ]
    },
    {
     "data": {
      "text/plain": "Loading pipeline components...:   0%|          | 0/5 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "054911c981ad4fb49a45c0fc0ff0ef64"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type clip_vision_model to instantiate a model of type clip. This is not supported for all configurations of models and can yield errors.\n",
      "A matching Triton is not available, some optimizations will not be enabled.\n",
      "Error caught was: No module named 'triton'\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "pipe = InpaintPipeline.from_pretrained(\n",
    "    'Fantasy-Studio/Paint-by-Example',\n",
    "    torch_dtype=torch.float16,\n",
    ")\n",
    "pipe.scheduler = DDIMScheduler.from_config(pipe.scheduler.config)\n",
    "pipe = pipe.to(device)\n",
    "pipe.enable_model_cpu_offload()\n",
    "pipe.enable_vae_slicing()\n",
    "pipe.enable_xformers_memory_efficient_attention()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from models.inpaint_image import generate_mask\n",
    "\n",
    "\n",
    "def save_images(*images, path=''):\n",
    "    for i, image in enumerate(images):\n",
    "        image.save(path + f'image{i}.png')\n",
    "\n",
    "def create_img(source_image, target_image) -> list:\n",
    "    source_image, target_image = source_image.resize((512, 512)), target_image.resize((512, 512))\n",
    "\n",
    "    return pipe(image=source_image,\n",
    "                mask_image=generate_mask(source_image, target_image, pipe),\n",
    "                example_image=target_image,\n",
    "                num_inference_steps=50).images[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-16T18:16:01.862558Z",
     "end_time": "2023-10-16T18:16:01.877560Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/50 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2ddbe4e125214fe7b9e459759cfe41c9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/50 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e396131b4ba3417a94bf630802fe9f4b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/50 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c52d17a7a29b440c814dff443aed273c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/50 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3ef922d83b2641ae9afe1886f8e83641"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/50 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c51b95fb8e994aa88ffc2749c3410c28"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/50 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8cab5e3a84cf493eae82d530e5bf0ec6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/50 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "72ac200f4a514cbaae2e94bf45a82f9b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/50 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "697e9688797c41ca8d6017e1005c9411"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/50 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4093654a82ea4a01b50bd407a8e39f37"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/50 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "db65b8bb76c44cdcb7e86785f6cdcc34"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/50 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e5375f37a66449b4b7bd9872695be4ae"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 13\u001B[0m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(images)):\n\u001B[0;32m     11\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m j \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(i \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m, \u001B[38;5;28mlen\u001B[39m(images)):\n\u001B[0;32m     12\u001B[0m         generated_images\u001B[38;5;241m.\u001B[39mextend([\n\u001B[1;32m---> 13\u001B[0m             \u001B[43mcreate_img\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimages\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mimages\u001B[49m\u001B[43m[\u001B[49m\u001B[43mj\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m,\n\u001B[0;32m     14\u001B[0m         ])\n\u001B[0;32m     16\u001B[0m save_images(generated_images, path\u001B[38;5;241m=\u001B[39moutput_folder)\n",
      "Cell \u001B[1;32mIn[5], line 8\u001B[0m, in \u001B[0;36mcreate_img\u001B[1;34m(source_image, target_image)\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcreate_img\u001B[39m(source_image, target_image) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mlist\u001B[39m:\n\u001B[0;32m      6\u001B[0m     source_image, target_image \u001B[38;5;241m=\u001B[39m source_image\u001B[38;5;241m.\u001B[39mresize((\u001B[38;5;241m512\u001B[39m, \u001B[38;5;241m512\u001B[39m)), target_image\u001B[38;5;241m.\u001B[39mresize((\u001B[38;5;241m512\u001B[39m, \u001B[38;5;241m512\u001B[39m))\n\u001B[1;32m----> 8\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mpipe\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimage\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msource_image\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      9\u001B[0m \u001B[43m                \u001B[49m\u001B[43mmask_image\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgenerate_mask\u001B[49m\u001B[43m(\u001B[49m\u001B[43msource_image\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget_image\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpipe\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     10\u001B[0m \u001B[43m                \u001B[49m\u001B[43mexample_image\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtarget_image\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     11\u001B[0m \u001B[43m                \u001B[49m\u001B[43mnum_inference_steps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m50\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mimages[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\hands-tracking\\lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001B[0m, in \u001B[0;36mcontext_decorator.<locals>.decorate_context\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    112\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[0;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m    114\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[1;32m--> 115\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\hands-tracking\\lib\\site-packages\\diffusers\\pipelines\\paint_by_example\\pipeline_paint_by_example.py:578\u001B[0m, in \u001B[0;36mPaintByExamplePipeline.__call__\u001B[1;34m(self, example_image, image, mask_image, height, width, num_inference_steps, guidance_scale, negative_prompt, num_images_per_prompt, eta, generator, latents, output_type, return_dict, callback, callback_steps)\u001B[0m\n\u001B[0;32m    575\u001B[0m     noise_pred \u001B[38;5;241m=\u001B[39m noise_pred_uncond \u001B[38;5;241m+\u001B[39m guidance_scale \u001B[38;5;241m*\u001B[39m (noise_pred_text \u001B[38;5;241m-\u001B[39m noise_pred_uncond)\n\u001B[0;32m    577\u001B[0m \u001B[38;5;66;03m# compute the previous noisy sample x_t -> x_t-1\u001B[39;00m\n\u001B[1;32m--> 578\u001B[0m latents \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscheduler\u001B[38;5;241m.\u001B[39mstep(noise_pred, t, latents, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mextra_step_kwargs)\u001B[38;5;241m.\u001B[39mprev_sample\n\u001B[0;32m    580\u001B[0m \u001B[38;5;66;03m# call the callback, if provided\u001B[39;00m\n\u001B[0;32m    581\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m i \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mlen\u001B[39m(timesteps) \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m ((i \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m) \u001B[38;5;241m>\u001B[39m num_warmup_steps \u001B[38;5;129;01mand\u001B[39;00m (i \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m) \u001B[38;5;241m%\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscheduler\u001B[38;5;241m.\u001B[39morder \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m):\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\hands-tracking\\lib\\site-packages\\diffusers\\schedulers\\scheduling_ddim.py:411\u001B[0m, in \u001B[0;36mDDIMScheduler.step\u001B[1;34m(self, model_output, timestep, sample, eta, use_clipped_model_output, generator, variance_noise, return_dict)\u001B[0m\n\u001B[0;32m    409\u001B[0m \u001B[38;5;66;03m# 2. compute alphas, betas\u001B[39;00m\n\u001B[0;32m    410\u001B[0m alpha_prod_t \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39malphas_cumprod[timestep]\n\u001B[1;32m--> 411\u001B[0m alpha_prod_t_prev \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39malphas_cumprod[prev_timestep] \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mprev_timestep\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m>\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfinal_alpha_cumprod\n\u001B[0;32m    413\u001B[0m beta_prod_t \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;241m-\u001B[39m alpha_prod_t\n\u001B[0;32m    415\u001B[0m \u001B[38;5;66;03m# 3. compute predicted original sample from predicted noise also called\u001B[39;00m\n\u001B[0;32m    416\u001B[0m \u001B[38;5;66;03m# \"predicted x_0\" of formula (12) from https://arxiv.org/pdf/2010.02502.pdf\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "input_folder = './cache/in/'\n",
    "output_folder = './cache/out/'\n",
    "\n",
    "paths = os.listdir(input_folder)\n",
    "random.shuffle(paths)\n",
    "\n",
    "images = [Image.open(input_folder + path) for path in paths]\n",
    "generated_images, couple = [], []\n",
    "\n",
    "for i in range(len(images)):\n",
    "    for j in range(i + 1, len(images)):\n",
    "        generated_images.extend([\n",
    "            create_img(images[i], images[j]),\n",
    "        ])\n",
    "\n",
    "save_images(generated_images, path=output_folder)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-12T22:18:37.395833Z",
     "end_time": "2023-10-12T22:18:37.398830Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "save_images(*generated_images, path=output_folder)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-16T18:20:23.842708Z",
     "end_time": "2023-10-16T18:20:25.133351Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
