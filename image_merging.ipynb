{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# !pip install git+https://github.com/Navu45/image-merging.git\n",
    "# !pip install git+https://github.com/ChaoningZhang/MobileSAM.git"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-12T21:28:29.687930Z",
     "end_time": "2023-10-12T21:28:29.717932Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from diffusers import DDIMScheduler\n",
    "from mobile_sam import sam_model_registry, SamAutomaticMaskGenerator\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "\n",
    "from models.inpaint_image import InpaintPipeline"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-12T21:38:04.393102Z",
     "end_time": "2023-10-12T21:38:04.399852Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: 'git lfs clone' is deprecated and will not be updated\n",
      "          with new flags from 'git clone'\n",
      "\n",
      "'git clone' has been updated in upstream Git to have comparable\n",
      "speeds to 'git lfs clone'.\n",
      "fatal: destination path 'MobileSAM' already exists and is not an empty directory.\n",
      "Error(s) during clone:\n",
      "git clone failed: exit status 128\n"
     ]
    }
   ],
   "source": [
    "!git lfs clone https://huggingface.co/dhkim2810/MobileSAM"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-12T21:28:37.121838Z",
     "end_time": "2023-10-12T21:28:37.245406Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-10-12T21:28:37.243904Z",
     "end_time": "2023-10-12T21:28:45.790056Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unet\\diffusion_pytorch_model.safetensors not found\n"
     ]
    },
    {
     "data": {
      "text/plain": "Loading pipeline components...:   0%|          | 0/5 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ff989138580f48859f5946ce8c935d7e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type clip_vision_model to instantiate a model of type clip. This is not supported for all configurations of models and can yield errors.\n",
      "A matching Triton is not available, some optimizations will not be enabled.\n",
      "Error caught was: No module named 'triton'\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "pipe = InpaintPipeline.from_pretrained(\n",
    "    'Fantasy-Studio/Paint-by-Example',\n",
    "    torch_dtype=torch.float16,\n",
    "    # local_files_only=True\n",
    ")\n",
    "pipe.scheduler = DDIMScheduler.from_config(pipe.scheduler.config)\n",
    "pipe = pipe.to(device)\n",
    "pipe.enable_model_cpu_offload()\n",
    "pipe.enable_vae_slicing()\n",
    "pipe.enable_xformers_memory_efficient_attention()\n",
    "\n",
    "model_type = \"vit_t\"\n",
    "sam_checkpoint = \"./MobileSAM/mobile_sam.pt\"\n",
    "mobile_sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
    "mobile_sam.to(device=device)\n",
    "mobile_sam.eval()\n",
    "mask_generator = SamAutomaticMaskGenerator(mobile_sam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "import cv2, numpy as np\n",
    "\n",
    "\n",
    "def generate_mask(source_image, target_image, pipe):\n",
    "    source_embeds = pipe.encode_image(source_image)\n",
    "    target_embeds = pipe.encode_image(target_image)\n",
    "    negative_mask_image = pipe.generate_mask(source_image,\n",
    "                                             height=source_image.height,\n",
    "                                             width=source_image.width,\n",
    "                                             target_prompt_embeds=target_embeds,\n",
    "                                             source_prompt_embeds=source_embeds,\n",
    "                                             num_maps_per_mask=10,\n",
    "                                             mask_encode_strength=0.5,\n",
    "                                             mask_thresholding_ratio=3.0,\n",
    "                                             num_inference_steps=50,\n",
    "                                             guidance_scale=1)\n",
    "    negative_mask_image = to_pil_image(negative_mask_image, 'L')\n",
    "    negative_mask_image = cv2.medianBlur(np.asarray(negative_mask_image), 59)\n",
    "    return to_pil_image(negative_mask_image, 'L')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-12T21:40:44.142449Z",
     "end_time": "2023-10-12T21:40:44.149200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/100 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c813691627ab43f38ac765d56a004ea4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/100 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5069228161ae48c58460f627b6680d53"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/100 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bfc8d01af86e4affb8212f21ad9471e9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/100 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4a75f18dc8b54a20ab7a598f64ef3e1e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/100 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c406bf977c8a4b718867aea93818e5fc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def save_images(*images):\n",
    "    for i, image in enumerate(images):\n",
    "        image.save(f'image{i}.png')\n",
    "\n",
    "def create_img(source_image, target_image) -> list:\n",
    "    source_image, target_image = source_image.resize((512, 512)), target_image.resize((512, 512))\n",
    "\n",
    "    return pipe(image=source_image,\n",
    "                mask_image=generate_mask(source_image, target_image, pipe),\n",
    "                example_image=target_image,\n",
    "                num_inference_steps=100).images[0]\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    with gr.Tab(\"\"):\n",
    "        with gr.Row():\n",
    "            source_image_input = gr.Image(type='pil')\n",
    "            target_image_input = gr.Image(type='pil')\n",
    "        with gr.Row():\n",
    "            image_output = gr.Image()\n",
    "        image_button = gr.Button(\"Generate image!\")\n",
    "    image_button.click(create_img, inputs=[source_image_input, target_image_input], outputs=image_output)\n",
    "\n",
    "demo.launch(debug=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-12T21:39:43.860714Z",
     "end_time": "2023-10-12T21:40:42.431981Z"
    },
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
